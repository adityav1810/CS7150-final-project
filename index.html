<!doctype html>
<html lang="en">
<head>
<title>Vision Transformers</title>
<meta property="og:title" content=An Image is worth 16 x 16 words" />
<meta name="twitter:title" content="An Image is worth 16 x 16 words" />
<meta name="description" content="Your project about your cool topic described right here." />
<meta property="og:description" content="Your project about your cool topic described right here." />
<meta name="twitter:description" content="Your project about your cool topic described right here." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

<!-- Add some styling -->
<style>
  table {
      border-collapse: collapse;
      width: 100%;
  }

  th, td {
      border: 1px solid #dddddd;
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
  }
</style>


</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">An Image is worth 16 x 16 words</nobr>
 <nobr class="widenobr">For CS 7150</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2>An Analysis of AN IMAGE IS WORTH 16X16 WORDS :</h2>
<p>Describe the paper and the big question about it that interests you.</p>
</div>
</div>
<div class="row">
<div class="col">

<h2>Literature Review</h2>

<p>Just as we have done in the role-playing exercise, analyze the paper from all perspectives.
</p>

<h2>Biography</h2>
<p>

  This team doesnt have well known names in it, However they are highly motivated researchers working at Google interested in applying deep learning techniques to vision related tasks. 
  Some members are now at different research groups but have collaborated together frequently in the past. 
  Another major research they conducted was "Scaling Vision Transformers to 22 billion parameters". 
  Most of the researches in this study work on scaling deep networks for vision tasks. <br>
<!-- 

Alexander Kolesnikov : Research Engineer @ Google Deepmind. Previously PhD at IST Austria, and applied math MSc at Moscow State University.<br>
Dirk Weissenborn :  Based out of Germany, Ex-Google, Meta, DeepMind. currently working at Inceptive Inc. <br>
Xiaohua Zhai : Seniour Staff Researcher at Google, Zurich. PhD from Peking University, China. Interested in vision, representation learning and generative modelling. <br>
Thomas Unterthiner : ML Engineer at Google, PhD from Johannes Kepler Universitat, Germany.<br>
Mostafa Dehghani : Research Scientist at Google, Ex-Apple. PhD from University of Amsterdam. <br>
Matthias Minderer : Senior Research Scientist at Google, PhD from Harvard under Christopher Harvey, Ex Neuroscience Major at ETH Zurich, also studied Biochemistry at University of Cambridge . Interested in representation learning of vision tasks. <br>
Georg Heigold : Research Scientist at Google, Mountain View , CA. Diploma in Physics from ETH Zurich. His research interests include automatic speech recognition, discriminative training, and log-linear modeling.<br>
Sylvain Gelly : Deep learning researcher at Google Brain, Zurich. Likes to work on reinforcement learning and dynamic programming. <br>
Jakob Uszkoreit : One of the authors of the original transformer paper, Maybe one of the most cited authors on this panel. Cofounded Inceptive  Ex Googler. <br>
Neil Houlsby : Senior Staff Research Scientist at Google, Zurich. PhD  in Computational Biology from University of Cambridge. Research interests include Bayesian ML, Cognitive Science and Active Learning. <br> -->
<table>
  <tr>
      <th>Name</th>
      <th> Photo </th>
      <th>Affiliation</th>
      <th>Contribution</th>
      
  </tr>
  <tr>
      <td>Alexey Dosovitskiy</td>
      <td><img src ="images/authors/alexd.jpeg" height="100px" width="100px"></td>
      <td>Google Research</td>
      <td>Ex Intel, left Google for an year to setup Inceptive with Jakob, recently returned back. PhD in Mathematics from Lomonosov Moscow State University. </td>

  </tr>
  <tr>
      <td>Lucas Beyer</td>
      <td><img src ="images/authors/lucasb.jpeg" height="100px" width="100px"></td>
      <td>Google Research</td>
      <td>Co-author, involved in the exploration and experimentation with Vision Transformers.French- German national from Belgium with PhD from RWTH Aachen.</td>
  </tr>
  <tr>
    <td>Alexander Kolesnikov</td>
    <td><img src ="images/authors/alexanderK.jpeg" height="100px" width="100px"></td>
    <td>Google Research</td>
    <td>Previously PhD at IST Austria, and applied math MSc at Moscow State University.</td>
</tr>
<tr>
  <td>Dirk Weissenborn</td>
  <td><img src ="images/authors/dirk.jpeg" height="100px" width="100px"></td>
  <td>Inceptive Inc.</td>
  <td>Based out of Germany, Ex-Google, Meta, DeepMind.</td>
</tr>
<tr>
  <td>Xiaohua Zhai</td>
  <td><img src ="images/authors/xiaohua.jpeg" height="100px" width="100px"></td>
  <td>Google Research</td>
  <td>Seniour Staff Researcher based out of Zurich. PhD from Peking University, China. Interested in vision, representation learning and generative modelling.</td>
</tr>
<tr>
  <td>Thomas Unterthiner</td>
  <td><img src ="images/authors/thomas.jpeg" height="100px" width="100px"></td>
  <td>Google Research</td>
  <td>ML Engineer , PhD from Johannes Kepler Universitat, Germany. Research interests include Compuational Biology, understanding deep networks, activation functions, emaluation metrics </td>
</tr>
<tr>
  <td>Mostafa Dehghani</td>
  <td><img src ="images/authors/mostafa.jpeg" height="100px" width="100px"></td>
  <td>Google Research</td>
  <td> Research Scientist, Ex-Apple. PhD from University of Amsterdam. </td>
</tr>
<tr>
  <td>Matthias Minderer</td>
  <td><img src ="images/authors/matthias.jpeg" height="100px" width="100px"></td>
  <td>Google Research</td>
  <td>PhD from Harvard under Christopher Harvey, Ex Neuroscience Major at ETH Zurich, also studied Biochemistry at University of Cambridge . Interested in representation learning of vision tasks.</td>
</tr>
<tr>
  <td>Georg Heigold</td>
  <td><img src ="images/authors/georg.jpeg" height="100px" width="100px"></td>
  <td>Google Research</td>
  <td>Diploma in Physics from ETH Zurich. His research interests include automatic speech recognition, discriminative training, and log-linear modeling. Ex-Apple</td>
</tr>
<tr>
  <td>Sylvain Gelly</td>
  <td><img src ="images/authors/sylvain.jpeg" height="100px" width="100px"></td>
  <td>Independent Researcher / Google Research</td>
  <td>Deep learning Researcher based out of Zurich. Likes to work on reinforcement learning and dynamic programming.</td>
</tr>
<tr>
  <td>Jakob Uszkoreit</td>
  <td><img src ="images/authors/jakob.jpeg" height="100px" width="100px"></td>
  <td>Co-founder @ Inceptive</td>
  <td>One of the authors of the original transformer paper, Maybe one of the most cited authors on this panel. Ex Googler.</td>
</tr>
<tr>
  <td>Neil Houlsby</td>
  <td><img src ="images/authors/neil.jpeg" height="100px" width="100px"></td>
  <td>Google Research</td>
  <td>PhD  in Computational Biology from University of Cambridge. Research interests include Bayesian ML, Cognitive Science and Active Learning.</td>
</tr>

  <!-- Add more rows for other authors -->
</table>
</p>
<h2>Social Impact</h2>
<p>
  Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.
</p>
<h2>Industry Applications</h2>
<p>
  Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.
</p>
<h2>Follow-on Research</h2>
<p>
  Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.
</p>
<h2>Peer Review</h2>
<p>
  Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.
</p>

<p>Optionally, in addition to a reading-based analysis, implement the ideas of the paper in code, and report on your findings.
</p>

<h3>References</h3>

<p><a name="bottou-1990">[1]</a> <a href="https://papers.baulab.info/Bottou-1990.pdf"
  >L&eacute;on Bottou and Patrick Gallinari.
  <em>A framework for the cooperation of learning algorithms.</em></a>
  Advances in neural information processing systems 3 (1990).
</p>

<h2>Team Members</h2>
                                                   
<p><ul>
 <li>Aditya Varshney</li>
 <li> Gega Darakhvelidze </li>
</ul></p>

  
</div><!--col-->
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://cs7150.baulab.info/">About CS 7150</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>
